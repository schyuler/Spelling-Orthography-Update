{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e089c10",
   "metadata": {},
   "source": [
    "# Spelling Orthography Update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b8bb52",
   "metadata": {},
   "source": [
    "This project uses machine learning to update text from an older spelling orthography to a modern spelling orthography. The focus on this project will be on updating the spelling orthography from the 1908 Chamorro Bible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2bed1",
   "metadata": {},
   "source": [
    "**Name:** Schyuler Lujan<br>\n",
    "**Date Started:** 6-Nov-2024<br>\n",
    "**Date Completed:** In Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e5fba6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a847e9",
   "metadata": {},
   "source": [
    "# Scrape Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87adbe75",
   "metadata": {},
   "source": [
    "Scrape the text data from the chamorrobible.org website and format the text into a dataset of unduplicated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29992ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All text can be found at this URL\n",
    "website = 'http://chamorrobible.org/download/YSantaBiblia-Chamorro-HTML.htm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76529ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(website)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d89eff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the text\n",
    "ch_bible_text = soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b81262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the text\n",
    "#print(ch_bible_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3091dd",
   "metadata": {},
   "source": [
    "# Clean Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f162993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers\n",
    "text_clean = re.sub(r\"\\d+\", \" \", ch_bible_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5928078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "text_clean = re.sub(r\"[^\\w\\s]\", \"\", text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d6dd170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize text by converting to lowercase\n",
    "text_clean = text_clean.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e367c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text by word and store in a list of duplicated words\n",
    "total_word_list = text_clean.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c9ad3",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73742877",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e755210e",
   "metadata": {},
   "source": [
    "### Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1995cc79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total word count: 132,875\n"
     ]
    }
   ],
   "source": [
    "# Get total word count\n",
    "total_word_count = len(total_word_list)\n",
    "print(f\"The total word count: {total_word_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2e21c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique word count: 11,193\n"
     ]
    }
   ],
   "source": [
    "# Get unique word count\n",
    "unique_word_list = set(total_word_list)\n",
    "print(f\"The unique word count: {len(unique_word_list):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ebee25",
   "metadata": {},
   "source": [
    "### Word Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "31e19421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average word length\n",
    "word_length = [] # Initialize list\n",
    "\n",
    "for word in total_word_list:\n",
    "    word_length.append(len(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "808b39c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 4.725388523047977 characters\n"
     ]
    }
   ],
   "source": [
    "average_word_length = sum(word_length) / total_word_count\n",
    "print(f\"Average word length: {average_word_length} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5e7ee868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest word: 22 characters\n",
      "Shortest word: 1 character\n"
     ]
    }
   ],
   "source": [
    "# Get maximum word length\n",
    "word_length.sort(reverse=True) # Sort in descending order\n",
    "max_word_length = word_length[0]\n",
    "min_word_length = word_length[-1]\n",
    "print(f\"Longest word: {max_word_length} characters\")\n",
    "print(f\"Shortest word: {min_word_length} character\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742f4029",
   "metadata": {},
   "source": [
    "### Character Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02102232",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = {} # Initialize dictionary for storing characters\n",
    "total_character_count = 0 # For holding the total character count\n",
    "\n",
    "# Character counts\n",
    "for word in total_word_list:\n",
    "    for char in word:\n",
    "        total_character_count += 1\n",
    "        if char in characters:\n",
    "            characters[char] += 1\n",
    "        else:\n",
    "            characters[char] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2085afed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of characters in the text: 627,886\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total number of characters in the text: {total_character_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236eed00",
   "metadata": {},
   "source": [
    "## Frequency analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ffb9c5",
   "metadata": {},
   "source": [
    "### Character Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f28f0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to a list of tuples before converting to dataframe\n",
    "character_list = [] # Initialize list\n",
    "for char in characters:\n",
    "    character_list.append((char, characters[char]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7162185e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Character  Frequency\n",
      "2          a     130786\n",
      "3          n      60208\n",
      "9          o      47056\n",
      "6          i      46099\n",
      "14         e      39671\n",
      "0          y      38423\n",
      "12         u      34416\n",
      "15         g      34305\n",
      "1          s      30192\n",
      "4          t      29560\n",
      "10         j      28684\n",
      "8          m      27442\n",
      "7          l      18041\n",
      "17         p       9827\n",
      "11         c       9349\n",
      "13         r       7984\n",
      "19         d       7472\n",
      "18         ñ       7411\n",
      "20         f       6352\n",
      "5          b       4211\n",
      "23         ü       4050\n",
      "16         h       3452\n",
      "25         q       1023\n",
      "22         v        870\n",
      "27         â        646\n",
      "24         á        160\n",
      "26         é         85\n",
      "28         ó         51\n",
      "21         ú         23\n",
      "29         í         18\n",
      "33         x         12\n",
      "30         ô          2\n",
      "31         z          2\n",
      "32         k          2\n",
      "34         ã          1\n"
     ]
    }
   ],
   "source": [
    "# Convert to dataframe and view results in descending order\n",
    "character_frequency_df = pd.DataFrame(character_list, columns=[\"Character\", \"Frequency\"])\n",
    "# Sort dataframe by frequency\n",
    "character_frequency_df.sort_values(by=\"Frequency\", ascending=False, inplace=True)\n",
    "print(character_frequency_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2725531a",
   "metadata": {},
   "source": [
    "### Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3f387408",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {} # Initialize dictionary to store word counts\n",
    "\n",
    "# Iterate through word list and count each word\n",
    "for word in total_word_list:\n",
    "    if word in words:\n",
    "        words[word] += 1\n",
    "    else:\n",
    "        words[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "59a8b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = [] # Initialize list\n",
    "for word in words:\n",
    "    word_frequencies.append((word, words[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3a0593bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Word  Frequency\n",
      "0            y      15477\n",
      "57          ya       7730\n",
      "83          na       4631\n",
      "10         gui       4123\n",
      "4         sija       3631\n",
      "9          yan       2958\n",
      "40          ni       2813\n",
      "15          si       2354\n",
      "181       para       1629\n",
      "41          ti       1487\n",
      "81          sa       1450\n",
      "171      güiya       1242\n",
      "39      taotao       1240\n",
      "216       anae       1117\n",
      "50         ayo       1087\n",
      "129     ilegña       1077\n",
      "130         nu       1061\n",
      "52         lao       1020\n",
      "53       guiya       1013\n",
      "73        todo        965\n",
      "153      jamyo        959\n",
      "183       yuus        848\n",
      "391       este        824\n",
      "239        güe        818\n",
      "137        pot        811\n",
      "55       jeova        749\n",
      "5371     jesus        681\n",
      "119      guajo        668\n",
      "114        nae        662\n",
      "17          un        654\n",
      "185       jago        599\n",
      "182         as        522\n",
      "90        jafa        510\n",
      "97        tano        476\n",
      "150          o        424\n",
      "206         yo        411\n",
      "531      locue        402\n",
      "352       esta        389\n",
      "460     guinin        386\n",
      "103   ilegñija        382\n",
      "60       jaane        364\n",
      "132        jao        364\n",
      "179       taya        344\n",
      "112      señot        330\n",
      "389     yaguin        326\n",
      "766       mato        320\n",
      "68       guaja        313\n",
      "395    magajet        298\n",
      "226       asta        296\n",
      "30         uno        295\n"
     ]
    }
   ],
   "source": [
    "# Convert to a dataframe\n",
    "word_frequencies_df = pd.DataFrame(word_frequencies, columns=[\"Word\", \"Frequency\"])\n",
    "word_frequencies_df.sort_values(by=\"Frequency\", ascending=False, inplace=True)\n",
    "# View top 100 words\n",
    "print(word_frequencies_df.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9441b",
   "metadata": {},
   "source": [
    "### Lexical Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ee2ab",
   "metadata": {},
   "source": [
    "Assess how many words are used more than once, verses the number of words used only one time in the entire text to understand the diversity of the text vs. amount of repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c3d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words occuring once vs. Repeated words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff94275",
   "metadata": {},
   "source": [
    "## N-Grams Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9baa36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original text and remove numbers\n",
    "text = re.sub(r\"\\d+\", \" \", ch_bible_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66046649",
   "metadata": {},
   "source": [
    "### Find most common word pairings (2 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6332a8",
   "metadata": {},
   "source": [
    "### Find most common phrases (3 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f7309",
   "metadata": {},
   "source": [
    "# Export Data to Create Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b59f2",
   "metadata": {},
   "source": [
    "A small, manually created dataset of sample pairs will be created from the text. It will contain the old orthography spelling mapped to the equivalent new orthography spelling, and this dataset will be used to train our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "76762b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export word frequency dataframe to CSV file\n",
    "word_frequencies_df.to_csv('chamorro_bible_words.csv', index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea14b3f",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6633ba9",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52ddc7",
   "metadata": {},
   "source": [
    "# Final Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d6b91",
   "metadata": {},
   "source": [
    "# Export Final Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8fe3ce",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6b282",
   "metadata": {},
   "source": [
    "# Opportunities for Future Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
